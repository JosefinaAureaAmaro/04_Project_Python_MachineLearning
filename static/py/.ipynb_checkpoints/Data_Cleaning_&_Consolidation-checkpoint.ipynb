{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> OECD Data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make a list of csvs titles that will be nested together\n",
    "# dl = download\n",
    "\n",
    "#to read csv of data\n",
    "\n",
    "## data source: OECD\n",
    "dl_avg_annual_hrs_worked_df = pd.read_csv('../data/OECD_Avg_annual_hours_worked_per_worker_original_file.csv')\n",
    "dl_avg_annual_wages_df = pd.read_csv('../data/OECD_Average_annual_wages_original_file.csv')\n",
    "dl_causes_of_mortality_df = pd.read_csv('../data/OECD_Causes_of_mortality_original_file.csv')\n",
    "# dl_composite_leading_indicators_df = pd.read_csv('../data/OECD_Compsite_Leading_Indicators_original_file.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level Data Cleaning & Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this dataset has two layer of filtering\n",
    "dl_causes_of_mortality_df = dl_causes_of_mortality_df.loc[dl_causes_of_mortality_df['Measure'] == 'Number of total deaths']\n",
    "dl_causes_of_mortality_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rename the 'value' column to indicate the content\n",
    "\n",
    "# list of column headers by df \n",
    "value_cols = ['Avg. Work Hours (Annual)','Avg. Wages (Annual)','Mortality Causes','CLI Values (Monthly)']\n",
    "# dict of dataframes \n",
    "oecd_dfs = {0: dl_avg_annual_hrs_worked_df, \n",
    "            1: dl_avg_annual_wages_df,\n",
    "            2: dl_causes_of_mortality_df\n",
    "#             3: dl_composite_leading_indicators_df\n",
    "           }\n",
    "\n",
    "## lists for editing dataframes\n",
    "list_of_cols_to_drop = [\"TIME\",\n",
    "                        \"YEA\",\n",
    "                        \"Unit Code\",\n",
    "                        \"EMPSTAT\",\n",
    "                        \"Frequency\",\n",
    "                        \"FREQUENCY\",\n",
    "                        \"Measure\",\n",
    "                        \"PowerCode Code\",\n",
    "                        \"PowerCode\",\n",
    "                        \"SERIES\",\n",
    "                        \"Reference Period Code\",\n",
    "                        \"Reference Period\",\n",
    "                        \"Flag Codes\",\n",
    "                        \"SUBJECT\",\n",
    "                        \"Reference\",\n",
    "                        \"VAR\",\n",
    "                        \"Flags\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "# iterate through dataframes \n",
    "while i < len(oecd_dfs):\n",
    "    # rename columns per dataframe\n",
    "    ## all edited dataframes are now stored in oecd_dfs object \n",
    "    oecd_dfs[i] = oecd_dfs[i].rename(columns= {\"COUNTRY\":\"COU\",\n",
    "                                 \"LOCATION\":\"COU\",\n",
    "                                 \"UNIT\":\"Unit\",\n",
    "                                 \"Currency\": \"Unit\",\n",
    "                                 \"Time\":\"Year\",\n",
    "                                 \"Variable\":\"Description\", \n",
    "                                 \"Subject\":\"Description\",\n",
    "                                 \"Employment status\":\"Description\",\n",
    "                                 \"Series\":\"Description\"\n",
    "                                 })\n",
    "\n",
    "    # change datat type of year col\n",
    "    oecd_dfs[i]['Year'] = pd.to_numeric(oecd_dfs[i]['Year'])\n",
    "    # to add a dataset col\n",
    "    oecd_dfs[i][\"Dataset\"] = value_cols[i]\n",
    "    \n",
    "    # drop columns per dataframe\n",
    "    for item in list_of_cols_to_drop: \n",
    "        # test if column exists in dataframe\n",
    "        if item in oecd_dfs[i].columns:\n",
    "            oecd_dfs[i] = oecd_dfs[i].drop(columns= item)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    # repostion columns in dataframe\n",
    "    # get a list of of columns in the dataframe\n",
    "    print(f\"before columns {list(oecd_dfs[i].columns)}\")\n",
    "    \n",
    "    # assign to df\n",
    "    oecd_dfs[i] = oecd_dfs[i][[\"Dataset\",\"COU\",\"Country\",\"Year\",\"Description\",\"Value\",\"Unit\"]]\n",
    "    \n",
    "    \n",
    "    print(f\"Completed df {i} of 3\")\n",
    "    print(f\"final columns {list(oecd_dfs[i].columns)}\")\n",
    "    print(\"=========================\")   \n",
    "    \n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to concatenate dataframes\n",
    "oecd_df = pd.concat([oecd_dfs[0],oecd_dfs[1],oecd_dfs[2]],ignore_index=True)\n",
    "print(f\"Combined all df\")\n",
    "print(\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_df = oecd_df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_df.to_csv('../resources/OECD_Dataframes.csv', sep=',' , encoding= 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OECD  Merge Ready to Happiness Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = ['Total employment','In 2018 constant prices at 2018 USD PPPs','All causes of death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove monthly report\n",
    "oecd_yearly_reports_df = oecd_df.loc[oecd_df['Dataset'] != 'CLI Values (Monthly)']\n",
    "\n",
    "print(descriptions)\n",
    "\n",
    "# to filter the datasets by the descriptions\n",
    "oecd_yearly_reports_df = oecd_yearly_reports_df.loc[oecd_df['Description'].isin(descriptions)].reset_index(drop=True)\n",
    "oecd_yearly_reports_df.tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Data Tables for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show that the same amount of countries in the description .value_counts(sort=True)\n",
    "oecd_dfs[0].loc[:,['Description',\"COU\"]].groupby(\"Description\")['COU'].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "actual_descriptions = ['Total employment','In 2018 constant prices at 2018 USD PPPs', 'All causes of death','Amplitude adjusted (CLI)']\n",
    "\n",
    "while i < len(oecd_dfs):\n",
    "    # show that the same amount of countries in the description\n",
    "    results =  oecd_dfs[i].loc[:,['Description',\"COU\"]].groupby(\"Description\")['COU'].nunique().sort_values(ascending=False)\n",
    "    actual = results.filter(items = [actual_descriptions[i]])\n",
    "    \n",
    "    print('=========')\n",
    "    print(\"Actual Description Used:\")\n",
    "    print(actual)\n",
    "    print('-------------------')\n",
    "    print(\"Unqiue COU by Description:\")\n",
    "    print(results)\n",
    "    \n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating the OECD tables into a Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make a list of years with a numeric data type for filtering tables\n",
    "years = [*range(2010,2018,1)]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oecd_dfs)-2\n",
    "oecd_dfs[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Consolidate Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OECD_pivot_tables=[]\n",
    "\n",
    "## CLI not included because it is an annual report\n",
    "\n",
    "for dfs in range(len(oecd_dfs)):\n",
    "    for year in range(len(years)):\n",
    "        \n",
    "        # to filter dataframes by description value\n",
    "        df = oecd_dfs[dfs].loc[(oecd_dfs[dfs]['Year'] == years[year]) & (oecd_dfs[dfs]['Description'] == descriptions[dfs])]\n",
    "        \n",
    "        \n",
    "        # to reshape the data\n",
    "        oecd = pd.pivot_table(df, values='Value', index=['COU','Country'], columns=['Dataset'], aggfunc= np.sum)\n",
    "    \n",
    "        # data cleaning\n",
    "        oecd_tables = oecd.dropna(axis=0).reset_index()\n",
    "    \n",
    "        # append to list\n",
    "        OECD_pivot_tables.append(oecd_tables)\n",
    "    \n",
    "        print(f\"Completed {dfs} Dataframe for year: {years[year]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to review pivot tables\n",
    "OECD_pivot_tables[23].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to slice list of pivot tables by year\n",
    "\n",
    "dataframes = [*range(len(OECD_pivot_tables))]\n",
    "print(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_per(source, step):\n",
    "    return [source[i::step] for i in range(step)]\n",
    "\n",
    "yearly_df = slice_per(dataframes,8)\n",
    "yearly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Pivot Tables for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to inner join the pivot tables per the indexes\n",
    "oecd_ml_df = []\n",
    "\n",
    "\n",
    "try:\n",
    "    for index in yearly_df:            \n",
    "        # to merge 3 pivot tables per dataset column\n",
    "        oecd_df_part1 = pd.merge(OECD_pivot_tables[index[0]], OECD_pivot_tables[index[(0+1)]], on=['COU','Country'], how='inner')\n",
    "\n",
    "        # to merge 3 pivot tables per dataset column\n",
    "        oecd_df_part2 = pd.merge(oecd_df_part1, OECD_pivot_tables[index[(0+2)]], on=['COU','Country'], how='inner')\n",
    "\n",
    "        print(f\"Completed merge of pivot table {index[0]} & {(index[0+1])} & {(index[0+2])}\")\n",
    "\n",
    "        oecd_ml_df.append(oecd_df_part2)\n",
    "        print(f\"Pivot Table created of indexes:{index}\")\n",
    "                   \n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_ml_df[4].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'green'> World Bank Data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read csv of data\n",
    "df= pd.read_csv('../../../WDIData.csv')\n",
    "\n",
    "#to read csv of country names\n",
    "df_country_names= pd.read_csv('../data/WDI_Country_Code_and_Names.csv',encoding = \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "#to read csv of indicators\n",
    "df_list_indicators = pd.read_csv('../data/WDI_list_of_reviewed_indicators.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to grab the headers of the dataset\n",
    "df_headers=list(df.columns.values)\n",
    "\n",
    "#only pull the headers that are years\n",
    "df_years = df_headers[-59:]\n",
    "\n",
    "#only select previous years before 2010\n",
    "df_years_drop = df_years[0:50]\n",
    "#to make column '2018' a list\n",
    "df_years_drop_2018 = list([df_years[-1]])\n",
    "\n",
    "# to combine lists of years into 1 drop line\n",
    "df_drop = df_years_drop + df_years_drop_2018\n",
    "\n",
    "#to drop the years and create a summarized df\n",
    "df_columns_removed = df.drop(df_drop,axis=1)\n",
    "df_columns_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning Country Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to preview df_country_names\n",
    "df_country_names.head()\n",
    "\n",
    "#make a list of country short name\n",
    "country_short_names = list(df_country_names['Short Name'])\n",
    "\n",
    "#filter df by short names list\n",
    "df_filter_cols_nd_cols_rem = df_columns_removed.loc[df_columns_removed['Country Name'].isin(country_short_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_cols_nd_cols_rem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators =  list(df_list_indicators['Indicator Name'])\n",
    "print(indicators)\n",
    "\n",
    "#filter by indicators\n",
    "df_countries_indiciator = df_filter_cols_nd_cols_rem.loc[df_filter_cols_nd_cols_rem['Indicator Name'].isin(indicators)]\n",
    "\n",
    "#remove unnessecary columns\n",
    "df_wdi = df_countries_indiciator.drop(columns='Indicator Code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wdi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(df_wdi.iloc[:,3:].columns)\n",
    "numeric_years = [int(i) for i in years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "world_bank_indicators = []\n",
    "\n",
    "\n",
    "while i < len(years):\n",
    "    \n",
    "    # to create a df of series\n",
    "    wdi_data = df_wdi[['Country Code','Country Name', 'Indicator Name', years[i]]]\n",
    "    wdi_data = wdi_data.rename(columns={'Country Code':'COU','Country Name':'Country'})\n",
    "    \n",
    "    \n",
    "    # to reshape the data\n",
    "    wdi = pd.pivot_table(wdi_data, values=years[i], index=['COU','Country'], columns=['Indicator Name'], aggfunc= np.sum)\n",
    "    wdi.reset_index()\n",
    "    \n",
    "    # data cleaning\n",
    "    wdi_df = wdi.dropna(axis=0, how='all').reset_index()    \n",
    "    \n",
    "    # append to list\n",
    "    world_bank_indicators.append(wdi_df)\n",
    "    \n",
    "    # to create csv\n",
    "    world_bank_indicators[i].to_csv(f'../../../WDI_Data_Happiness_Table_{years[i]}.csv', sep=',' , encoding= 'utf-8', index=False)\n",
    "    \n",
    "    print(f\"Complete Dataframe for year: {years[i]}\")\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_bank_indicators[6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_bank_indicators[4].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> To Combine both datasets </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(world_bank_indicators))\n",
    "print(len(oecd_ml_df))\n",
    "\n",
    "## Both datasets are the same length, thus we can merge them to each other "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OECD data has less rows, thus we will perform an inner merge between the World Bank Data and the OECD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "\n",
    "ml_datasets = []\n",
    "\n",
    "while i < len(oecd_ml_df):\n",
    "    \n",
    "    # to merge 3 pivot tables per dataset column\n",
    "    ml_df = pd.merge(oecd_ml_df[i], world_bank_indicators[i], on=['COU','Country'], how='inner')\n",
    "    ml_df['Year'] = numeric_years[i]\n",
    "    ml_datasets.append(ml_df)\n",
    "    \n",
    "    # to create csv\n",
    "    ml_datasets[i].to_csv(f'../resources/Machine_Learning_Dataset_{years[i]}.csv', sep=',' , encoding= 'utf-8', index=False)\n",
    "    \n",
    "    print(f'Completed dataset {i} of 7')\n",
    "    \n",
    "    i +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_datasets[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='magenta'> UN Happiness Report </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read csv un happiness data names\n",
    "un_happiness_report = pd.read_csv('../data/world_happiness_report_2019_original_file.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years is from earlier in the report\n",
    "years\n",
    "numeric_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_happiness_report = un_happiness_report.rename(columns={'Country name':'Country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_happiness_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "happiness_datasets = []\n",
    "\n",
    "while i < len(years):\n",
    "    \n",
    "    # to filter by year to fit other datasets 2010 to 2017\n",
    "    un_happiness_report_merge = un_happiness_report.loc[un_happiness_report['Year'] == numeric_years[i]]\n",
    "    happiness_merge_ready = un_happiness_report_merge.drop(columns=['Year'])\n",
    "    \n",
    "    \n",
    "    # to merge 3 pivot tables per dataset column\n",
    "    life_ml_df = pd.merge(ml_datasets[i], happiness_merge_ready, on=['COU','Country'], how='inner')\n",
    "    \n",
    "    happiness_datasets.append(life_ml_df)\n",
    "    \n",
    "    # to create csv\n",
    "    happiness_datasets[i].to_csv(f'../resources/Machine_Learning_Dataset_{years[i]}.csv', sep=',' , encoding= 'utf-8', index=False)\n",
    "    \n",
    "    \n",
    "    print(f\"Merged UN Year {years[i]} with OECD & WDI Data\")\n",
    "    \n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_datasets[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_datasets[7].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'orange'> To Combine OECD Data with UN Happiness Report </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check to see if OECD has countries that UN report does not\n",
    "\n",
    "oecd_cou_series= list(set(oecd_yearly_reports_df['COU']))\n",
    "UN_cou_series= list(set(un_happiness_report['COU']))\n",
    "\n",
    "print(f\"OECD COU: {len(oecd_cou_series)}\")\n",
    "print(f\"UN COU: {len(UN_cou_series)}\")\n",
    "\n",
    "same_cou = len(set(oecd_cou_series) & set(UN_cou_series))\n",
    "\n",
    "print(f\"Number countries that are the same {same_cou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_happiness_report.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_yearly_reports_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_yearly_reports_df.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to merge OECD Data with UN Happiness Report\n",
    "oecd_happiness_df = pd.merge(oecd_yearly_reports_df, un_happiness_report, on=['COU','Country','Year'], how='inner')\n",
    "oecd_happiness_df['Year'] = pd.to_numeric(oecd_happiness_df['Year'])\n",
    "oecd_happiness_df.to_csv('../resources/OECD_Happiness_Merge_Dataframes.csv', sep=',' , encoding= 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_happiness_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_happiness_df.groupby('Country')['Year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_happiness_df.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata] *",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
